# Domain-Adaptive FAS & Background Reconstruction Resources

**Scope.** Methods, datasets, and protocols related to multimodal deception detection.



---

## 📄 Datasets

| Year | Title | Venue | PDF/ArXiv | Code | Notes |
|:---:|:------|:-----:|:---------:|:----:|:-----:|
| 2025 | Multimodal Lie Detection Dataset Based on Chinese Dialogue | Journal of Image and Graphics | [pdf](https://arxiv.org/abs/2407.12274)| [code](https://aip.seu.edu.cn/2024/1219/c54084a515309/page.htm) | - |
| 2024 | MDPE: A Multimodal Deception Dataset with Personality and Emotional Characteristic | MM | [pdf](https://arxiv.org/abs/2407.12274) | [code](https://github.com/cai-cong/MDPE) | - |
| 2024 | Depth-Augmented Background Completion | ECCV | [arXiv](https://arxiv.org/abs/2407.00001) | - | — | depth, reconstruction |

> 模板行（复制后改字段）：  
> `| YEAR | Paper Title | VENUE | [pdf](LINK) or [arXiv](LINK) | [code](LINK) or - | DATASET | TAGS/NOTES |`

---

## 📦 Papers

| Name | Modalities | Link | Notes |
|:----:|:----------:|:----:|:-----:|
| OULU-NPU | RGB | [link](https://example.com) | Standard FAS benchmark |
| WMCA | RGB / Depth / IR / Thermal | [link](https://example.com) | Multi-modal, many attack types |

> 模板行：  
> `| NAME | MODALITIES | [link](URL) | NOTE |`

---

## 🧪 Benchmarks & Protocols (brief)
- Common metrics: EER, APCER/BPCER, HTER, AUC.
- Cross-domain setups: leave-one-domain-out, unseen-attack types, unseen sensors.

---

## 📜 License
- Code in this repo: MIT  
- List content (tables & README text): CC-BY-4.0
